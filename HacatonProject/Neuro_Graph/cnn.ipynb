{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b11bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f5c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных (в данном случае, CIFAR-100)\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar100.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530b249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar100.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "model = models.Sequential([\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.UpSampling2D(size=(2, 2)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(100, activation='softmax') \n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb880cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7adf027a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 184s 234ms/step - loss: 3.9116 - accuracy: 0.0977 - val_loss: 3.3980 - val_accuracy: 0.1809\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 3.1337 - accuracy: 0.2306 - val_loss: 2.9660 - val_accuracy: 0.2728\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 183s 235ms/step - loss: 2.7345 - accuracy: 0.3108 - val_loss: 2.6957 - val_accuracy: 0.3208\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 184s 235ms/step - loss: 2.4296 - accuracy: 0.3730 - val_loss: 2.5501 - val_accuracy: 0.3473\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 183s 235ms/step - loss: 2.1932 - accuracy: 0.4226 - val_loss: 2.4070 - val_accuracy: 0.3878\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 1.9877 - accuracy: 0.4691 - val_loss: 2.3877 - val_accuracy: 0.3962\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 1.8081 - accuracy: 0.5046 - val_loss: 2.3647 - val_accuracy: 0.3964\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 1.6431 - accuracy: 0.5457 - val_loss: 2.4117 - val_accuracy: 0.4080\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 1.4953 - accuracy: 0.5787 - val_loss: 2.4587 - val_accuracy: 0.4050\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 1.3597 - accuracy: 0.6144 - val_loss: 2.5753 - val_accuracy: 0.4001\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 1.2180 - accuracy: 0.6469 - val_loss: 2.6566 - val_accuracy: 0.3997\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 1.1063 - accuracy: 0.6751 - val_loss: 2.7641 - val_accuracy: 0.3959\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.9989 - accuracy: 0.7023 - val_loss: 2.8731 - val_accuracy: 0.3813\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.9137 - accuracy: 0.7258 - val_loss: 2.9500 - val_accuracy: 0.3922\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.8299 - accuracy: 0.7492 - val_loss: 3.1742 - val_accuracy: 0.3830\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.7582 - accuracy: 0.7668 - val_loss: 3.2438 - val_accuracy: 0.3777\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.7099 - accuracy: 0.7816 - val_loss: 3.4480 - val_accuracy: 0.3838\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.6549 - accuracy: 0.7961 - val_loss: 3.5069 - val_accuracy: 0.3760\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.6221 - accuracy: 0.8075 - val_loss: 3.6418 - val_accuracy: 0.3848\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 183s 234ms/step - loss: 0.5662 - accuracy: 0.8237 - val_loss: 3.9302 - val_accuracy: 0.3707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be801986d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, batch_size=64, epochs=20, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5487776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 30ms/step - loss: 3.9302 - accuracy: 0.3707\n",
      "Test accuracy: 0.37070000171661377\n"
     ]
    }
   ],
   "source": [
    "# Оценка производительности модели на тестовых данных\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb86578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('HackNeuro.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c94d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = keras.models.load_model('HackNeuro.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loaded.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe050424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.3674 - accuracy: 0.4110\n",
      "Test accuracy: 0.41100001335144043\n"
     ]
    }
   ],
   "source": [
    "# Оценка производительности загруженной модели на тестовых данных\n",
    "test_loss, test_acc = model_loaded.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e587f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "100\n",
      "[[1.12006524e-06 1.30110702e-05 1.31442933e-03 7.87001627e-05\n",
      "  9.96809686e-04 2.08340483e-04 1.41953824e-05 5.29445315e-05\n",
      "  2.03665020e-03 1.81280298e-03 3.43648526e-06 3.77286255e-04\n",
      "  4.18783777e-04 9.04714034e-06 1.69181676e-05 1.48247916e-03\n",
      "  1.29709512e-01 1.79886524e-06 3.50522343e-03 9.81822261e-04\n",
      "  4.70175037e-05 6.26621186e-05 6.22130930e-04 2.15415412e-07\n",
      "  9.65725667e-06 4.26835701e-04 1.19077595e-06 9.16466024e-03\n",
      "  1.37136062e-03 5.93976467e-04 1.19969896e-04 7.32217959e-05\n",
      "  4.60406727e-06 9.37401666e-04 1.08703377e-03 6.41241277e-05\n",
      "  1.98977777e-05 4.00800527e-05 6.41217513e-04 8.07288779e-06\n",
      "  5.17529607e-01 9.74719785e-03 1.77922088e-03 3.85900103e-06\n",
      "  7.61296891e-04 2.02772743e-03 2.28704908e-03 5.75388199e-08\n",
      "  8.69048199e-06 7.28560900e-09 1.37717972e-04 6.06676971e-04\n",
      "  7.72185926e-11 4.09518339e-12 2.56134284e-04 7.70163238e-02\n",
      "  2.19809735e-07 6.89833450e-06 1.29794287e-07 1.59533811e-04\n",
      "  3.13151194e-09 1.19057620e-06 2.49286217e-07 6.48921414e-05\n",
      "  1.53699925e-03 2.24965112e-03 2.15724241e-02 1.78819493e-04\n",
      "  5.26388305e-07 8.29131807e-07 7.12151668e-05 8.51430144e-08\n",
      "  1.45940781e-02 7.77980767e-06 6.52867413e-07 7.67642559e-05\n",
      "  2.47038370e-05 1.29638251e-03 3.32964264e-04 3.62704828e-04\n",
      "  1.19283743e-01 1.76936192e-05 6.14695495e-08 1.82713240e-08\n",
      "  7.19985878e-03 1.23859081e-07 4.15583588e-02 1.00710941e-02\n",
      "  8.25823750e-04 2.46628770e-05 2.29766806e-06 2.55009900e-06\n",
      "  8.36925974e-05 2.95940292e-04 3.19195632e-03 1.01460991e-08\n",
      "  9.39318852e-07 4.32124175e-03 4.43280733e-05 4.37236886e-05]]\n",
      "0.5175296\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка изображения\n",
    "image = load_img('image (5).png', target_size=(32, 32))\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = image.astype('float32') / 255.0\n",
    "\n",
    "# Получение предсказания модели\n",
    "prediction = model.predict(image)\n",
    "print(len(prediction[0]))\n",
    "print(prediction)\n",
    "\n",
    "max_value = max(prediction[0])\n",
    "max_index = list(prediction[0]).index(max_value)\n",
    "print(max_value)\n",
    "print(max_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
